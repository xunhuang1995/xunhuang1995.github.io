{\rtf1\ansi\ansicpg1252\cocoartf2761
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 Times-Bold;\f1\froman\fcharset0 Times-Roman;\f2\froman\fcharset0 Times-Italic;
}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red0\green0\blue233;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c0\c0\c93333;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid301\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid4}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}}
\margl1440\margr1440\vieww34660\viewh17680\viewkind0
\deftab720
\pard\pardeftab720\sa321\partightenfactor0

\f0\b\fs48 \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Xun Huang\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 \strokec2 Generative AI Researcher | Multimodal Models & Image Synthesis\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0\cf3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\ul \outl0\strokewidth0 \strokec3 Bio\cf0 \ulnone \strokec2 \
\ls1\ilvl0\cf3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\ul \outl0\strokewidth0 \strokec3 Research\cf0 \ulnone \strokec2 \
\ls1\ilvl0\cf3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\ul \outl0\strokewidth0 \strokec3 Publications\cf0 \ulnone \strokec2 \
\ls1\ilvl0\cf3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\ul \outl0\strokewidth0 \strokec3 Projects\cf0 \ulnone \strokec2 \
\ls1\ilvl0\cf3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "file:///Users/xuhuang/Projects/homepage_v2/Xun_Huang_CV.pdf"}}{\fldrslt \expnd0\expndtw0\kerning0
\ul \outl0\strokewidth0 \strokec3 CV}}\cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \
\ls1\ilvl0\cf3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\ul \outl0\strokewidth0 \strokec3 Contact\cf0 \ulnone \strokec2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf0 About Me\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 \strokec2 I am Xun Huang, a Generative AI researcher with over 8 years of experience in the field, focusing on pixel generation and multimodal models. My work has been pivotal in advancing the state-of-the-art in image synthesis.\
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf0 \strokec2 Research Interests\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 \strokec2 My research interests include:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls2\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Multimodal Large Language Models (LLMs)\
\ls2\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Generative Adversarial Networks (GANs)\
\ls2\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Neural Image Synthesis\
\ls2\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 AI for Creative Applications\
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf0 Publications\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls3\ilvl0
\f1\b0\fs24 \cf3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\ul \outl0\strokewidth0 \strokec3 Title of Paper 1\cf0 \ulnone \strokec2 , Conference Name, Year\
\ls3\ilvl0\cf3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\ul \outl0\strokewidth0 \strokec3 Title of Paper 2\cf0 \ulnone \strokec2 , Journal Name, Year\
\ls3\ilvl0\cf3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\ul \outl0\strokewidth0 \strokec3 Title of Paper 3\cf0 \ulnone \strokec2 , Conference Name, Year\
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf0 Publications\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\partightenfactor0
\cf0 \
\pard\pardeftab720\sa280\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://example.com/paper1"}}{\fldrslt 
\f0\b\fs28 \cf3 \ul \ulc3 \strokec3 Advances in Multimodal Learning Systems}}
\f0\b\fs28 \
\pard\pardeftab720\sa240\partightenfactor0

\f2\i\b0\fs24 \cf0 Conference on Neural Information Processing Systems (NeurIPS), 2024
\f1\i0 \strokec2 \
This paper introduces novel techniques in multimodal learning, integrating vision and language models for enhanced performance.\
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\partightenfactor0
\cf0 \
\pard\pardeftab720\sa280\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://example.com/paper2"}}{\fldrslt 
\f0\b\fs28 \cf3 \ul \ulc3 \strokec3 Generative Adversarial Networks for Image Synthesis}}
\f0\b\fs28 \
\pard\pardeftab720\sa240\partightenfactor0

\f2\i\b0\fs24 \cf0 International Conference on Machine Learning (ICML), 2023
\f1\i0 \strokec2 \
This work presents a new architecture for GANs, achieving state-of-the-art results in image synthesis tasks.\
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf0 \strokec2 Projects\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 \strokec2 Here are some of my recent projects:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls4\ilvl0\cf3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\ul \outl0\strokewidth0 \strokec3 Project 1: Multimodal Model for Image Editing\cf0 \ulnone \strokec2 \
\ls4\ilvl0\cf3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\ul \outl0\strokewidth0 \strokec3 Project 2: Pixel Generation AI\cf0 \ulnone \strokec2 \
\ls4\ilvl0\cf3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\ul \outl0\strokewidth0 \strokec3 Project 3: Generative AI Toolkit\cf0 \ulnone \strokec2 \
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs36 \cf0 Contact\
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0\fs24 \cf0 \strokec2 Email: {\field{\*\fldinst{HYPERLINK "mailto:xunhuang1995@gmail.com"}}{\fldrslt \cf3 \ul \ulc3 \strokec3 xunhuang1995@gmail.com}}\
\'a9 2024 Xun Huang | {\field{\*\fldinst{HYPERLINK "https://github.com/XunHuang"}}{\fldrslt \cf3 \ul \ulc3 \strokec3 GitHub}} | {\field{\*\fldinst{HYPERLINK "https://linkedin.com/in/XunHuang"}}{\fldrslt \cf3 \ul \ulc3 \strokec3 LinkedIn}}\
\
How to refer to Felix in publications}